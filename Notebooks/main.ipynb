{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd03f998-a862-4b61-be69-10e203a50329",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 17:54:08.020927: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-03 17:54:09.139228: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2024-12-03 17:54:09.139361: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2024-12-03 17:54:09.139371: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from peft import PeftModel\n",
    "\n",
    "# Load the tokenizer\n",
    "summarization_tokenizer = AutoTokenizer.from_pretrained(\"./lora_summarization_model\")\n",
    "\n",
    "# Load the base model\n",
    "base_model_name = \"t5-small\"  # Replace with your original base model if different\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(base_model_name)\n",
    "\n",
    "# Load the LoRA fine-tuned model\n",
    "lora_model = PeftModel.from_pretrained(base_model, \"./lora_summarization_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c79cced3-3665-4cf7-b5a1-ff1c10a5c460",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, MBartForConditionalGeneration, AutoModelForSeq2SeqLM\n",
    "from peft import PeftModel\n",
    "\n",
    "# Load the translation model and tokenizer\n",
    "translation_model = MBartForConditionalGeneration.from_pretrained(\"./translation_model\")\n",
    "translation_tokenizer = AutoTokenizer.from_pretrained(\"./translation_model\")\n",
    "\n",
    "# Load the summarization model and tokenizer\n",
    "summarization_tokenizer = AutoTokenizer.from_pretrained(\"./lora_summarization_model\")\n",
    "base_model_name = \"t5-small\"  # Replace with your original base model if different\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(base_model_name)\n",
    "lora_model = PeftModel.from_pretrained(base_model, \"./lora_summarization_model\")\n",
    "\n",
    "# Translation function\n",
    "def translate_text(text):\n",
    "    prompt = f\"Translate the text to English: {text}\"\n",
    "    inputs = translation_tokenizer(prompt, return_tensors=\"pt\", max_length=128, truncation=True)\n",
    "    outputs = translation_model.generate(**inputs)\n",
    "    translation = translation_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return translation\n",
    "\n",
    "def pipeline(input_text):\n",
    "    \n",
    "    # Translate text\n",
    "    translated_text = translate_text(input_text)\n",
    "    print(\"Translated text: \",translated_text)\n",
    "    \n",
    "    # Summarize translated text\n",
    "    prompt = f\"summarize this text: {translated_text}\"\n",
    "    inputs = summarization_tokenizer(\n",
    "            prompt,\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=512,\n",
    "            truncation=True\n",
    "        )    \n",
    "    # Generate summary\n",
    "    outputs = lora_model.generate(\n",
    "        **inputs,\n",
    "        max_length=150,\n",
    "        min_length=20,\n",
    "        num_beams=4,\n",
    "        no_repeat_ngram_size=2,\n",
    "        early_stopping=True\n",
    "    )\n",
    "\n",
    "    summary = summarization_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abf64ed1-2167-4e2c-9d8a-de7aeaf3a1c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated text:  WASHINGTON, DC – With Congress returning this week to make one final move before it closes, it faces a major deadline on December 20 to avoid shutting down the government. Democrats and Republicans seem resigned to pushing through a decision, or CR, that would temporarily fund the government until early 2025 – probably in March – when they run out of time to agree on full funding this year.\n",
      "\n",
      "Summary: Congress faces a major deadline on December 20 to avoid shutting down the government. Democrats and Republicans seem resigned to pushing through an CR decision that would temporarily fund government until early 2025 - probably in March – when they run out of time to agree on full funding this year.\n"
     ]
    }
   ],
   "source": [
    "example_text = \"\"\"واشنطن – مع عودة الكونجرس هذا الأسبوع للقيام بموجة أخيرة من النشاط قبل أن يختتم جلسته، فإنه يواجه موعدًا نهائيًا رئيسيًا في 20 ديسمبر لتجنب إغلاق الحكومة.\n",
    "\n",
    "يبدو أن الديمقراطيين والجمهوريين مستسلمون لتمرير قرار مستمر، أو CR، من شأنه أن يمول الحكومة مؤقتًا حتى أوائل عام 2025 - على الأرجح في مارس - حيث ينفد الوقت أمامهم للتوصل إلى اتفاق تمويل كامل هذا العام. ولم يتفق الطرفان حتى على مستوى الإنفاق الإجمالي للسنة المالية الجديدة، ناهيك عن كيفية تخصيص الأموال عبر أجزاء من الحكومة.\n",
    "\n",
    "ألمح زعيم الأغلبية في مجلس الشيوخ تشاك شومر، ديمقراطي من ولاية نيويورك، إلى حتمية مشروع قانون قصير الأجل يوم الاثنين، قائلاً: \"نحن بحاجة إلى إبقاء الأحكام المثيرة للخلاف وغير الضرورية خارج أي تمديد للتمويل الحكومي، وإلا فسيكون من الصعب تمرير مشروع قانون\". CR في الوقت المناسب.\n",
    "\n",
    "وبالنسبة للجمهوريين، فإن هذا سيف ذو حدين.\n",
    "\n",
    "الجانب الإيجابي بالنسبة للجمهوريين في تحديد الموعد النهائي هو أنهم سيكون لديهم المزيد من النفوذ لتشكيل التمويل الحكومي في العام الجديد، مع عودة الرئيس المنتخب دونالد ترامب إلى البيت الأبيض وسيطرة الحزب الجمهوري على مجلس الشيوخ والحفاظ على أغلبية ضيقة في مجلس النواب.\n",
    "\n",
    "الجانب السلبي الكبير هو أنه سيحدد موعدًا نهائيًا حاسمًا في وقت مبكر من رئاسة ترامب، مما قد يستغرق وقتًا ثمينًا بعيدًا عن تأكيد مرشحيه من خلال مجلس الشيوخ ومن مشروع قانون الحزب الكبير الذي يتطلع إليه الجمهوريون لتمديد تخفيضاته الضريبية وتعزيز الهجرة. وأجندة أمن الحدود.\n",
    "\n",
    "وأضاف كينيدي أنه من المرجح أن يعلق الكونجرس \"30 [مليار دولار] إلى 40 مليار دولار من الإغاثة في حالات الكوارث\" إلى الجمهورية التشيكية، بما في ذلك تمويل الولايات التي ضربتها الأعاصير هذا العام. وقال: \"لن يكون ذلك كافيا، لكنه سيكون كافيا للبدء\".\"\"\"\n",
    "\n",
    "result = pipeline(example_text)\n",
    "print(\"\\nSummary:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47edc79b-08e9-4010-9da2-677d1bcdb78d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m125"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
