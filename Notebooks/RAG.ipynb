{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "668ed0a2",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "249e2110-1e1e-4efa-b000-adac843367f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame loaded successfully!\n",
      "                                             summary     topic  \\\n",
      "0  Transport in a cattle carriage, smell of meat ...  Politics   \n",
      "1  Marble zebra stripes, pompous buildings: Sinde...  Politics   \n",
      "2  Oskar Lafontaine resigns as party chairman of ...  Politics   \n",
      "3  The roots of poverty lie in the past. Haiti is...  Politics   \n",
      "4  Black-yellow is not yet the dream coalition th...  Politics   \n",
      "\n",
      "                                               title        date  \\\n",
      "0        Auschwitz: Memories of a Holocaust Survivor  00/01/2010   \n",
      "1  Municipalities in Need (3): Sindelfingen - Bey...  00/01/2010   \n",
      "2  Staff debate on the left - who is coming to La...  00/01/2010   \n",
      "3             History of Haiti - Napoleon's disgrace  00/01/2010   \n",
      "4  Black-and-yellow cabinet - Merkel's team in th...  00/01/2010   \n",
      "\n",
      "                                     translated_text  \n",
      "0  Transport in a cattle carriage, smell of meat ...  \n",
      "1  Marble zebra stripes, pompous buildings: Sinde...  \n",
      "2  This Monday, when the country’s left-wing lead...  \n",
      "3  The portrait of 1791 shows Haiti’s national he...  \n",
      "4  New heads and old acquaintances: Angela Merkel...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the CSV file path\n",
    "csv_file_path = \"/Users/anirudhhegde/Desktop/Northeastern University/Natural Language Processing/Project/RAG-Based-Multilingual-News-Retrieval/dataset.csv\"\n",
    "\n",
    "# Load the CSV as a DataFrame\n",
    "try:\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    print(\"DataFrame loaded successfully!\")\n",
    "    print(df.head())  # Display the first few rows of the DataFrame\n",
    "except Exception as e:\n",
    "    print(f\"Error loading the CSV file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41d343b5-c9cc-4def-bb96-8bdd5526311c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>translated_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Transport in a cattle carriage, smell of meat ...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>Auschwitz: Memories of a Holocaust Survivor</td>\n",
       "      <td>00/01/2010</td>\n",
       "      <td>Transport in a cattle carriage, smell of meat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marble zebra stripes, pompous buildings: Sinde...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>Municipalities in Need (3): Sindelfingen - Bey...</td>\n",
       "      <td>00/01/2010</td>\n",
       "      <td>Marble zebra stripes, pompous buildings: Sinde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oskar Lafontaine resigns as party chairman of ...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>Staff debate on the left - who is coming to La...</td>\n",
       "      <td>00/01/2010</td>\n",
       "      <td>This Monday, when the country’s left-wing lead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The roots of poverty lie in the past. Haiti is...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>History of Haiti - Napoleon's disgrace</td>\n",
       "      <td>00/01/2010</td>\n",
       "      <td>The portrait of 1791 shows Haiti’s national he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Black-yellow is not yet the dream coalition th...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>Black-and-yellow cabinet - Merkel's team in th...</td>\n",
       "      <td>00/01/2010</td>\n",
       "      <td>New heads and old acquaintances: Angela Merkel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             summary     topic  \\\n",
       "0  Transport in a cattle carriage, smell of meat ...  Politics   \n",
       "1  Marble zebra stripes, pompous buildings: Sinde...  Politics   \n",
       "2  Oskar Lafontaine resigns as party chairman of ...  Politics   \n",
       "3  The roots of poverty lie in the past. Haiti is...  Politics   \n",
       "4  Black-yellow is not yet the dream coalition th...  Politics   \n",
       "\n",
       "                                               title        date  \\\n",
       "0        Auschwitz: Memories of a Holocaust Survivor  00/01/2010   \n",
       "1  Municipalities in Need (3): Sindelfingen - Bey...  00/01/2010   \n",
       "2  Staff debate on the left - who is coming to La...  00/01/2010   \n",
       "3             History of Haiti - Napoleon's disgrace  00/01/2010   \n",
       "4  Black-and-yellow cabinet - Merkel's team in th...  00/01/2010   \n",
       "\n",
       "                                     translated_text  \n",
       "0  Transport in a cattle carriage, smell of meat ...  \n",
       "1  Marble zebra stripes, pompous buildings: Sinde...  \n",
       "2  This Monday, when the country’s left-wing lead...  \n",
       "3  The portrait of 1791 shows Haiti’s national he...  \n",
       "4  New heads and old acquaintances: Angela Merkel...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89f87d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   summary          3000 non-null   object\n",
      " 1   topic            3000 non-null   object\n",
      " 2   title            3000 non-null   object\n",
      " 3   date             3000 non-null   object\n",
      " 4   translated_text  3000 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 117.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f21cb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for the articles...\n",
      "FAISS index contains 3000 items.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "# Load the SentenceTransformer model for multilingual embeddings\n",
    "embedding_model = SentenceTransformer('multi-qa-mpnet-base-dot-v1')\n",
    "\n",
    "# Generate embeddings for the 'translated_text'\n",
    "print(\"Generating embeddings for the articles...\")\n",
    "df['embedding'] = df['translated_text'].apply(lambda x: embedding_model.encode(x, normalize_embeddings = True))\n",
    "\n",
    "# Convert embeddings into a numpy array\n",
    "embeddings = np.vstack(df['embedding'].values)\n",
    "\n",
    "# Initialize FAISS index for vector storage and search\n",
    "dimension = embeddings.shape[1]  # Embedding dimension\n",
    "faiss_index = faiss.IndexFlatL2(dimension)  # L2 distance metric\n",
    "faiss_index.add(embeddings)  # Add embeddings to the FAISS index\n",
    "print(f\"FAISS index contains {faiss_index.ntotal} items.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e2328c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_query(query):\n",
    "    \"\"\"Generate embedding for a user query.\"\"\"\n",
    "    return embedding_model.encode(query, normalize_embeddings =True)\n",
    "\n",
    "# Example user query\n",
    "# query = \"America donald trump election\"\n",
    "query = 'climate change summit renewable energy policy global emissions 2024'\n",
    "query_embedding = encode_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c247a9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Articles:\n",
      "                                                  title  \\\n",
      "2331  The 'glaciargate' brings another shock to heat...   \n",
      "2009  The EU is unable to overcome the failure of Co...   \n",
      "1954  Spain promotes a 30% increase in European emis...   \n",
      "1504                 A 'community' to live from the air   \n",
      "2821     Climate: the new industrial carbon tax targets   \n",
      "\n",
      "                                                  topic  \\\n",
      "2331  The Committee recommends that the State party ...   \n",
      "2009  The Committee recommends that the State party ...   \n",
      "1954  The Committee recommends that the State party ...   \n",
      "1504                                   diario catalunya   \n",
      "2821                                           a-la-une   \n",
      "\n",
      "                                        translated_text  \\\n",
      "2331  The Intergovernmental Panel on Climate Change ...   \n",
      "2009  The European Environment Ministers failed to o...   \n",
      "1954  Teresa Ribera is a special case: the Secretary...   \n",
      "1504  The López family consumes about 11,000 kilowat...   \n",
      "2821  A detailed note from the Agency for the Enviro...   \n",
      "\n",
      "                                                summary  \n",
      "2331  The IPCC's error on the date of extinction of ...  \n",
      "2009  Italy and Poland refuse to increase emission c...  \n",
      "1954  Teresa Ribera: 'We do not want a trade war wit...  \n",
      "1504  100 people join forces to buy a windmill - the...  \n",
      "2821  A confidential report estimates the financial ...  \n"
     ]
    }
   ],
   "source": [
    "def search_faiss(query_embedding, top_k=5):\n",
    "    \"\"\"Retrieve top-k most similar articles from FAISS index.\"\"\"\n",
    "    query_embedding = np.array([query_embedding])  # Convert query to 2D array\n",
    "    distances, indices = faiss_index.search(query_embedding, top_k)\n",
    "    return indices[0], distances[0]\n",
    "\n",
    "# Search for the most relevant articles\n",
    "top_k = 5\n",
    "indices, distances = search_faiss(query_embedding, top_k=top_k)\n",
    "\n",
    "# Retrieve articles based on indices\n",
    "retrieved_articles = df.iloc[indices]\n",
    "print(\"Retrieved Articles:\")\n",
    "print(retrieved_articles[['title','topic', 'translated_text', 'summary']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04712798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titles and All Similarity Scores:\n",
      "                                                  title  cosine_similarity  \\\n",
      "2331  The 'glaciargate' brings another shock to heat...           0.539866   \n",
      "2009  The EU is unable to overcome the failure of Co...           0.539767   \n",
      "1954  Spain promotes a 30% increase in European emis...           0.527164   \n",
      "1504                 A 'community' to live from the air           0.499522   \n",
      "2821     Climate: the new industrial carbon tax targets           0.484886   \n",
      "\n",
      "      query_summary_similarity  news_summary_similarity  \n",
      "2331                  0.364418                 0.504805  \n",
      "2009                  0.413350                 0.572294  \n",
      "1954                  0.353279                 0.443289  \n",
      "1504                  0.348424                 0.460392  \n",
      "2821                  0.347860                 0.431925  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from bert_score import score\n",
    "import pandas as pd\n",
    "\n",
    "# Calculate cosine similarity and BERTScore for retrieved articles\n",
    "def analyze_similarity(query, query_embedding, retrieved_articles, embeddings, indices):\n",
    "    # Step 1: Cosine Similarity between query and retrieved articles\n",
    "    retrieved_embeddings = embeddings[indices]\n",
    "    cosine_similarities = cosine_similarity([query_embedding], retrieved_embeddings).flatten()\n",
    "    \n",
    "    # Add similarity scores to the retrieved articles\n",
    "    retrieved_articles = retrieved_articles.copy()\n",
    "    retrieved_articles['cosine_similarity'] = cosine_similarities\n",
    "    \n",
    "    # Sort articles by cosine similarity score\n",
    "    retrieved_articles = retrieved_articles.sort_values(by='cosine_similarity', ascending=False)\n",
    "\n",
    "    # Step 2: BERTScore Similarity for query-summaries and news-summaries\n",
    "    if \"summary\" not in retrieved_articles.columns or \"translated_text\" not in retrieved_articles.columns:\n",
    "        raise ValueError(\"DataFrame must contain 'summary' and 'translated_text' columns for similarity comparison.\")\n",
    "\n",
    "    # Task 1: Similarity Between Query and Summaries\n",
    "    query_list = [query] * len(retrieved_articles)  # Repeat the query for all summaries\n",
    "    _, _, F1_query_summary = score(\n",
    "        retrieved_articles[\"summary\"].tolist(),\n",
    "        query_list,\n",
    "        lang=\"en\",\n",
    "        model_type=\"bert-base-uncased\"\n",
    "    )\n",
    "    retrieved_articles[\"query_summary_similarity\"] = F1_query_summary.tolist()\n",
    "\n",
    "    # Task 2: Similarity Between News Articles (translated_text) and Summaries\n",
    "    _, _, F1_news_summary = score(\n",
    "        retrieved_articles[\"summary\"].tolist(),\n",
    "        retrieved_articles[\"translated_text\"].tolist(),\n",
    "        lang=\"en\",\n",
    "        model_type=\"bert-base-uncased\"\n",
    "    )\n",
    "    retrieved_articles[\"news_summary_similarity\"] = F1_news_summary.tolist()\n",
    "\n",
    "    # Step 3: Return only the title and similarity scores\n",
    "    result_df = retrieved_articles[[\n",
    "        \"title\", \"cosine_similarity\", \"query_summary_similarity\", \"news_summary_similarity\"\n",
    "    ]]\n",
    "\n",
    "    print(\"Titles and All Similarity Scores:\")\n",
    "    print(result_df)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "# Usage example (you'll need to provide `query`, `query_embedding`, `retrieved_articles`, `embeddings`, `indices`):\n",
    "final_df = analyze_similarity(query, query_embedding, retrieved_articles, embeddings, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d70717",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m125"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
