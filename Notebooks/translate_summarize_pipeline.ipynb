{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c45d67e8-2b8a-40f8-a51b-5b386aee0f3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from datasets import load_dataset\n",
    "from langdetect import detect\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b9d7d71-e5ad-4d69-971d-0ee2d8e7af63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 700 records from MLSUM dataset for language: de\n",
      "Loading 700 records from MLSUM dataset for language: es\n",
      "Loading 700 records from MLSUM dataset for language: fr\n",
      "Loading 700 records from MLSUM dataset for language: ru\n",
      "Loading 700 records from MLSUM dataset for language: tu\n",
      "Filtered Data with Language Detection:\n",
      "                                                text  \\\n",
      "0  Transport im Viehwaggon, Fleischgeruch in der ...   \n",
      "1  Marmorner Zebrastreifen, pomp├╢se Geb├дude: Sind...   \n",
      "2  Wenn an diesem Montag die Landesvorsitzenden d...   \n",
      "\n",
      "                                             summary    topic  \\\n",
      "0  Transport im Viehwaggon, Fleischgeruch in der ...  politik   \n",
      "1  Marmorner Zebrastreifen, pomp├╢se Geb├дude: Sind...  politik   \n",
      "2  Oskar Lafontaine gibt den Parteivorsitz der Li...  politik   \n",
      "\n",
      "                                               title        date language  \n",
      "0  So war Auschwitz: Erinnerungen einer Holocaust...  00/01/2010       de  \n",
      "1  Kommunen in Not (3): Sindelfingen - Jenseits g...  00/01/2010       de  \n",
      "2  Personaldebatte bei der Linken - Wer kommt nac...  00/01/2010       de  \n"
     ]
    }
   ],
   "source": [
    "# An empty list to store DataFrames for each language\n",
    "dataframes = []\n",
    "\n",
    "# Define the list of language configurations\n",
    "languages = ['de', 'es', 'fr', 'ru', 'tu']\n",
    "\n",
    "# Number of records to download for each language\n",
    "records_to_download = 700\n",
    "\n",
    "# Load the dataset for each language configuration\n",
    "for lang in languages:\n",
    "    print(f\"Loading {records_to_download} records from MLSUM dataset for language: {lang}\")\n",
    "    dataset = load_dataset('mlsum', lang, split=f'train[:{records_to_download}]', trust_remote_code=True)\n",
    "\n",
    "    # Convert to pandas DataFrame for easier manipulation\n",
    "    df = pd.DataFrame(dataset)\n",
    "\n",
    "    # Add a column for language\n",
    "    df['language'] = lang\n",
    "\n",
    "    # Append the DataFrame to the list\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "data = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Filter to keep relevant columns\n",
    "data = data.drop('url', axis=1, errors='ignore')\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(\"Filtered Data with Language Detection:\")\n",
    "print(data.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dd2fcef-966f-4470-898c-241772fb626d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(data)\n",
    "\n",
    "# Split dataset for training/evaluation (80% train, 20% validation)\n",
    "dataset = dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "659b2ea4-e998-4580-9b38-17a98b8beeb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 07:09:46.551813: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-03 07:09:47.623313: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2024-12-03 07:09:47.623451: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2024-12-03 07:09:47.623463: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from transformers import MBartForConditionalGeneration, MBart50Tokenizer\n",
    "\n",
    "# Load translation model and tokenizer\n",
    "translation_model_name = \"facebook/mbart-large-50-many-to-one-mmt\"\n",
    "translation_model = MBartForConditionalGeneration.from_pretrained(translation_model_name)\n",
    "translation_tokenizer = MBart50Tokenizer.from_pretrained(translation_model_name, src_lang=\"en_XX\", tgt_lang=\"en_XX\")\n",
    "\n",
    "def translate_text(text):\n",
    "    prompt = f\"Translate the text to English: {text}\"\n",
    "    inputs = translation_tokenizer(prompt, return_tensors=\"pt\", max_length=128, truncation=True)\n",
    "    outputs = translation_model.generate(**inputs)\n",
    "    translation = translation_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a218403-134e-46e5-af0b-f4f5530060f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating Summaries: 100%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИ| 2800/2800 [1:42:13<00:00,  2.19s/it]  \n",
      "Translating Summaries: 100%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИ| 700/700 [26:45<00:00,  2.29s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd644531226c4f76b800e66bba482280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/2800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec19e4b180804e77846d5068a8664de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/700 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the translation function to translate the summaries\n",
    "def translate_summaries(dataset):\n",
    "    translated_summaries = []\n",
    "    for summary in tqdm(dataset[\"summary\"], desc=\"Translating Summaries\"):\n",
    "        translated_summary = translate_text(summary)\n",
    "        translated_summaries.append(translated_summary)\n",
    "    return translated_summaries\n",
    "\n",
    "# Translate the summaries in the dataset\n",
    "translated_summaries_train = translate_summaries(dataset[\"train\"])\n",
    "translated_summaries_test = translate_summaries(dataset[\"test\"])\n",
    "\n",
    "# Now add the translated summaries as a new column\n",
    "dataset[\"train\"] = dataset[\"train\"].add_column(\"translated_summary\", translated_summaries_train)\n",
    "dataset[\"test\"] = dataset[\"test\"].add_column(\"translated_summary\", translated_summaries_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "debe63d4-f690-4e10-80bc-430912cfb6c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating Input Texts: 100%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИ| 175/175 [5:29:34<00:00, 112.99s/it]  \n",
      "Translating Input Texts: 100%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИ| 44/44 [1:26:11<00:00, 117.53s/it]\n"
     ]
    }
   ],
   "source": [
    "# Define the translation function\n",
    "def translate_texts(texts, batch_size=16):\n",
    "    \"\"\"\n",
    "    Translate a list of texts in batches.\n",
    "    \n",
    "    Args:\n",
    "        texts (list): List of strings to translate.\n",
    "        batch_size (int): Number of texts to translate at a time.\n",
    "\n",
    "    Returns:\n",
    "        list: Translated texts.\n",
    "    \"\"\"\n",
    "    translated_texts = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Translating Input Texts\"):\n",
    "        batch = texts[i:i + batch_size]\n",
    "        # Assume translate_text is a function that translates a single text\n",
    "        translated_batch = [translate_text(text) for text in batch]\n",
    "        translated_texts.extend(translated_batch)\n",
    "    return translated_texts\n",
    "\n",
    "# Translate the input texts in the train and test datasets\n",
    "translated_texts_train = translate_texts(dataset[\"train\"][\"text\"])\n",
    "translated_texts_test = translate_texts(dataset[\"test\"][\"text\"])\n",
    "\n",
    "# Add the translated input texts as a new column\n",
    "dataset[\"train\"] = dataset[\"train\"].add_column(\"translated_text\", translated_texts_train)\n",
    "dataset[\"test\"] = dataset[\"test\"].add_column(\"translated_text\", translated_texts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71105836-fac6-40d3-9bc1-d3079657497f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text', 'summary', 'topic', 'title', 'date', 'language', 'translated_summary', 'translated_text']\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8c4692c-360a-43b3-950d-343ff17f9c25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc8f94d737804e6dac7e4cd9b18c63c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eb7975ca2b3433aaa333a62061d3268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/700 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_data_for_summarization(examples):\n",
    "    return {\n",
    "        \"input_text\": [f\"Summarize the following text: {text}\" for text in examples[\"translated_text\"]],\n",
    "        \"target_text\": examples[\"translated_summary\"]  # Use the translated summary here\n",
    "    }\n",
    "\n",
    "# Apply the preprocessing function to the dataset\n",
    "summarization_dataset = dataset.map(preprocess_data_for_summarization, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8b65d45-3815-4db7-8dc0-168b9eea0845",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (summarization_dataset[\"train\"][\"translated_summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b41fdb9-b76c-48f7-a86b-6ff41f141aa1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4868825f6086496f84c7f08aca85dbe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93324d8828d440bb9f06a53c8c32ad66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/700 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model, PeftType, TaskType\n",
    "from transformers import TrainingArguments, Trainer, AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "# Load summarization model and tokenizer\n",
    "summarization_model_name = \"t5-small\"  # Use T5 or any other Seq2Seq model\n",
    "summarization_model = AutoModelForSeq2SeqLM.from_pretrained(summarization_model_name)\n",
    "summarization_tokenizer = AutoTokenizer.from_pretrained(summarization_model_name)\n",
    "\n",
    "# Define LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"q\", \"v\"],  # LoRA applied to specific layers\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM\n",
    ")\n",
    "\n",
    "# Apply LoRA to the model\n",
    "lora_model = get_peft_model(summarization_model, lora_config)\n",
    "\n",
    "# Tokenize data for training\n",
    "def tokenize_function(examples):\n",
    "    inputs = summarization_tokenizer(\n",
    "        examples[\"input_text\"], max_length=512, truncation=True, padding=\"max_length\", return_tensors=\"pt\"\n",
    "    )\n",
    "    labels = summarization_tokenizer(\n",
    "        examples[\"target_text\"], max_length=128, truncation=True, padding=\"max_length\", return_tensors=\"pt\"\n",
    "    )[\"input_ids\"]\n",
    "    inputs[\"labels\"] = labels\n",
    "    return inputs\n",
    "\n",
    "tokenized_dataset = summarization_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61a48b7d-30b2-48e5-8ebb-21f6676c38d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tokenized_dataset[\"train\"]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fb2864c-1346-4c7c-bef5-7fee6e97bc7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ЁЯдЧ Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/var/tmp/ipykernel_129512/1657301929.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2100' max='2100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2100/2100 1:13:45, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.310400</td>\n",
       "      <td>0.925675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.924700</td>\n",
       "      <td>0.818257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.837200</td>\n",
       "      <td>0.770432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.818700</td>\n",
       "      <td>0.744333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.834000</td>\n",
       "      <td>0.733954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.798200</td>\n",
       "      <td>0.730913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2100, training_loss=1.7337668827601842, metrics={'train_runtime': 4427.5871, 'train_samples_per_second': 3.794, 'train_steps_per_second': 0.474, 'total_flos': 2288962555084800.0, 'train_loss': 1.7337668827601842, 'epoch': 6.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./summarization_lora_results\",\n",
    "    evaluation_strategy=\"epoch\",  # Evaluate at the end of each epoch\n",
    "    save_strategy=\"epoch\",  # Save at the end of each epoch\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=6,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    load_best_model_at_end=True,  # Load the best model at the end of training\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=lora_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=summarization_tokenizer,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87711e70-6c55-43c0-a731-866a2b02e765",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pipeline(input_text):\n",
    "    \n",
    "    # Translate text\n",
    "    translated_text = translate_text(input_text)\n",
    "    print(\"Translated text: \",translated_text)\n",
    "    \n",
    "    # Summarize translated text\n",
    "    prompt = f\"summarize this text: {translated_text}\"\n",
    "    inputs = summarization_tokenizer(\n",
    "            prompt,\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=512,\n",
    "            truncation=True\n",
    "        )    \n",
    "    # Generate summary\n",
    "    outputs = lora_model.generate(\n",
    "        **inputs,\n",
    "        max_length=150,\n",
    "        min_length=20,\n",
    "        num_beams=4,\n",
    "        no_repeat_ngram_size=2,\n",
    "        early_stopping=True\n",
    "    )\n",
    "\n",
    "    summary = summarization_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0d4fbf8-52ae-4a89-aa1d-df3ee15d28ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated text:  The sun rose gently on the horizon, casting a golden light over the rolling hills. The birds began to sing, their melody filling the fresh morning air. In a small village nestled at the foot of the mountains, the inhabitants were already busy with their daily tasks. Children ran through the cobbled streets, laughing and playing hide-and-seek, while adults opened the sides of their stone houses.\n",
      "\n",
      "Summary: children ran through the cobbled streets, laughing and playing hide-and-seek, while adults opened the sides of their stone houses.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "example_text = \"\"\"Le soleil se levait doucement ├а l'horizon, projetant une lumi├иre dor├йe sur les collines ondulantes. Les oiseaux commen├зaient ├а chanter, leur m├йlodie emplissant l'air frais du matin. Dans un petit village nich├й au pied des montagnes, les habitants s'affairaient d├йj├а ├а leurs t├вches quotidiennes. Les enfants couraient dans les ruelles pav├йes, riant et jouant ├а cache-cache, tandis que les adultes ouvraient les volets de leurs maisons en pierre.\n",
    "\n",
    "Marie, une jeune femme aux cheveux bruns et aux yeux p├йtillants, sortit de sa maison en tenant un panier rempli de fleurs fra├оches. Elle aimait commencer sa journ├йe en cueillant des fleurs dans les champs voisins. Les couleurs vives des coquelicots, des marguerites et des bleuets illuminaient le paysage. Tandis qu'elle marchait, elle salua ses voisins avec un sourire chaleureux.\n",
    "\n",
    "Au centre du village se trouvait une petite place anim├йe o├╣ les commer├зants installaient leurs ├йtals. Le boulanger, avec sa toque blanche et ses mains enfarin├йes, sortait des baguettes croustillantes du four. L'odeur du pain chaud se m├кlait aux ar├┤mes des fruits frais et des herbes vendues par les marchands. Les discussions anim├йes des villageois cr├йaient une ambiance joyeuse et conviviale.\n",
    "\n",
    "Non loin de l├а, un vieux moulin ├а eau tournait lentement, aliment├й par un ruisseau limpide. Les enfants aimaient s'y rassembler pour jeter des cailloux dans l'eau ou observer les poissons qui nageaient sous la surface. Les plus ├вg├йs racontaient des histoires sur les l├йgendes locales, parlant de chevaliers courageux et de tr├йsors cach├йs dans les montagnes environnantes.\n",
    "\n",
    "├А la lisi├иre du village, un berger conduisait son troupeau de moutons vers les p├вturages verdoyants. Le tintement des clochettes attach├йes aux cous des animaux r├йsonnait dans l'air tranquille. Les chiens de berger, alertes et ob├йissants, veillaient ├а ce qu'aucun mouton ne s'├йloigne. Le berger, avec son b├вton en bois et son chapeau de paille, semblait en parfaite harmonie avec la nature.\n",
    "\n",
    "Pendant ce temps, dans une petite ferme ├а la p├йriph├йrie du village, un fermier et sa femme travaillaient dans leur potager. Ils plantaient des l├йgumes et arrosaient les plantes sous le regard curieux d'un chat paresseux qui somnolait sur une\"\"\"\n",
    "result = pipeline(example_text)\n",
    "print(\"\\nSummary:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "738301a2-00ec-4fa8-bc2b-54cd263fe84d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated text:  Washington - As the Congress returns to its final activity before the session ends this week, it faces a crucial deadline of December 20 to stop the government shutdown. The Democrats and the Republicans seem to have resigned to pass a sustained motion, or CR, that will provide temporary financing to the government early in 2025 - possibly in March - because they have no time to make a full financing deal this year.\n",
      "\n",
      "Summary: Democrats and the Republicans seem to have resigned to pass a sustained motion, or CR, that will provide temporary financing to the government early in 2025.\n"
     ]
    }
   ],
   "source": [
    "example_text = \"\"\"рд╡рд╛рд╢рд┐рдВрдЧрдЯрди - рдЬреИрд╕рд╛ рдХрд┐ рдХрд╛рдВрдЧреНрд░реЗрд╕ рдЗрд╕ рд╕рдкреНрддрд╛рд╣ рд╕рддреНрд░ рд╕рдорд╛рдкреНрдд рд╣реЛрдиреЗ рд╕реЗ рдкрд╣рд▓реЗ рдЖрдЦрд┐рд░реА рдЧрддрд┐рд╡рд┐рдзрд┐ рдХреЗ рд▓рд┐рдП рд▓реМрдЯреА рд╣реИ, рдЙрд╕реЗ рд╕рд░рдХрд╛рд░реА рд╢рдЯрдбрд╛рдЙрди рдХреЛ рд░реЛрдХрдиреЗ рдХреЗ рд▓рд┐рдП 20 рджрд┐рд╕рдВрдмрд░ рдХреА рдорд╣рддреНрд╡рдкреВрд░реНрдг рд╕рдордп рд╕реАрдорд╛ рдХрд╛ рд╕рд╛рдордирд╛ рдХрд░рдирд╛ рдкрдбрд╝ рд░рд╣рд╛ рд╣реИред\n",
    "\n",
    "рдРрд╕рд╛ рдкреНрд░рддреАрдд рд╣реЛрддрд╛ рд╣реИ рдХрд┐ рдбреЗрдореЛрдХреНрд░реЗрдЯ рдФрд░ рд░рд┐рдкрдмреНрд▓рд┐рдХрди рдиреЗ рдПрдХ рд╕рддрдд рдкреНрд░рд╕реНрддрд╛рд╡, рдпрд╛ рд╕реАрдЖрд░ рдкрд╛рд░рд┐рдд рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдЗрд╕реНрддреАрдлрд╛ рджреЗ рджрд┐рдпрд╛ рд╣реИ, рдЬреЛ 2025 рдХреА рд╢реБрд░реБрдЖрдд рдореЗрдВ рд╕рд░рдХрд╛рд░ рдХреЛ рдЕрд╕реНрдерд╛рдпреА рд░реВрдк рд╕реЗ рд╡рд┐рддреНрдд рдкреЛрд╖рд┐рдд рдХрд░реЗрдЧрд╛ - рд╕рдВрднрд╡рддрдГ рдорд╛рд░реНрдЪ - рдХреНрдпреЛрдВрдХрд┐ рдЙрдирдХреЗ рдкрд╛рд╕ рдЗрд╕ рд╡рд░реНрд╖ рдкреВрд░реНрдг рд╡рд┐рддреНрддрдкреЛрд╖рдг рд╕реМрджрд╛ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рд╕рдордп рдирд╣реАрдВ рдмрдЪрд╛ рд╣реИред рджреЛрдиреЛрдВ рдкрд╛рд░реНрдЯрд┐рдпрд╛рдБ рдирдП рд╡рд┐рддреНрддреАрдп рд╡рд░реНрд╖ рдХреЗ рд▓рд┐рдП рд╕рдордЧреНрд░ рд╡реНрдпрдп рд╕реНрддрд░ рдкрд░ рднреА рд╕рд╣рдордд рдирд╣реАрдВ рд╣реБрдИ рд╣реИрдВ, рд╕рд░рдХрд╛рд░ рдХреЗ рд╡рд┐рднрд┐рдиреНрди рд╣рд┐рд╕реНрд╕реЛрдВ рдореЗрдВ рдзрди рдХреИрд╕реЗ рдЖрд╡рдВрдЯрд┐рдд рдХрд┐рдпрд╛ рдЬрд╛рдП, рдЗрд╕рдХреА рддреЛ рдмрд╛рдд рд╣реА рдЫреЛрдбрд╝ рджреЗрдВред\n",
    "\n",
    "\n",
    "рд░рд┐рдкрдмреНрд▓рд┐рдХрди рдХреЗ рд▓рд┐рдП, рдпрд╣ рджреЛрдзрд╛рд░реА рддрд▓рд╡рд╛рд░ рд╣реИред\n",
    "\n",
    "рд╕рдордп рд╕реАрдорд╛ рддрдп рдХрд░рдиреЗ рдореЗрдВ рд░рд┐рдкрдмреНрд▓рд┐рдХрди рдХреЗ рд▓рд┐рдП рд▓рд╛рдн рдпрд╣ рд╣реИ рдХрд┐ рдирдП рд╕рд╛рд▓ рдореЗрдВ рд╕рд░рдХрд╛рд░реА рдлрдВрдбрд┐рдВрдЧ рдХреЛ рдЖрдХрд╛рд░ рджреЗрдиреЗ рдХреЗ рд▓рд┐рдП рдЙрдирдХреЗ рдкрд╛рд╕ рдЕрдзрд┐рдХ рд▓рд╛рдн рд╣реЛрдЧрд╛, рдХреНрдпреЛрдВрдХрд┐ рдирд┐рд░реНрд╡рд╛рдЪрд┐рдд рд░рд╛рд╖реНрдЯреНрд░рдкрддрд┐ рдбреЛрдирд╛рд▓реНрдб рдЯреНрд░рдореНрдк рд╡реНрд╣рд╛рдЗрдЯ рд╣рд╛рдЙрд╕ рдореЗрдВ рд▓реМрдЯ рдЖрдПрдВрдЧреЗ рдФрд░ рдЬреАрдУрдкреА рд╕реАрдиреЗрдЯ рдкрд░ рдирд┐рдпрдВрддреНрд░рдг рдХрд░ рд▓реЗрдЧреА рдФрд░ рдПрдХ рд╕рдВрдХреАрд░реНрдг рд╕рджрди рдмрд╣реБрдордд рдмрдирд╛рдП рд░рдЦреЗрдЧреАред\n",
    "\n",
    "рдмрдбрд╝рд╛ рдирдХрд╛рд░рд╛рддреНрдордХ рдкрдХреНрд╖ рдпрд╣ рд╣реИ рдХрд┐ рдЗрд╕рд╕реЗ рдЯреНрд░рдВрдк рдХреЗ рд░рд╛рд╖реНрдЯреНрд░рдкрддрд┐ рдмрдирдиреЗ рдХреА рд╢реБрд░реБрдЖрдд рдореЗрдВ рд╣реА рдПрдХ рдорд╣рддреНрд╡рдкреВрд░реНрдг рд╕рдордп рд╕реАрдорд╛ рддрдп рд╣реЛ рдЬрд╛рдПрдЧреА, рдЬрд┐рд╕рд╕реЗ рд╕рдВрднрд╛рд╡рд┐рдд рд░реВрдк рд╕реЗ рд╕реАрдиреЗрдЯ рдХреЗ рдорд╛рдзреНрдпрдо рд╕реЗ рдЙрдирдХреЗ рдЙрдореНрдореАрджрд╡рд╛рд░реЛрдВ рдХреА рдкреБрд╖реНрдЯрд┐ рдХрд░рдиреЗ рдФрд░ рд░рд┐рдкрдмреНрд▓рд┐рдХрди рджреНрд╡рд╛рд░рд╛ рдЙрдирдХреЗ рдХрд░ рдХрдЯреМрддреА рдХреЛ рдмрдврд╝рд╛рдиреЗ рдФрд░ рдЙрдирдХреЗ рдЖрд╡реНрд░рдЬрди рдХреЛ рдЖрдЧреЗ рдмрдврд╝рд╛рдиреЗ рдХреЗ рд▓рд┐рдП рдмрдбрд╝реЗ рдкрд╛рд░реНрдЯреА-рд▓рд╛рдЗрди рдмрд┐рд▓ рд╕реЗ рдореВрд▓реНрдпрд╡рд╛рди рд╕рдордп рдмрд░реНрдмрд╛рдж рд╣реЛ рдЬрд╛рдПрдЧрд╛ред рдФрд░ рд╕реАрдорд╛ рд╕реБрд░рдХреНрд╖рд╛ рдПрдЬреЗрдВрдбрд╛ред\n",
    "\n",
    "\"рд╣рдореЗрдВ рдПрдХ рд╣реА рд╕рдордп рдореЗрдВ рдмрд╣реБрдд рд╕рд╛рд░реА рдЪреАрдЬреЗрдВ рдХрд░рдиреА рд╣реИрдВ,\" рд╣рд╛рдЙрд╕ рдореЗрдЬреЙрд░рд┐рдЯреА рд▓реАрдбрд░ рд╕реНрдЯреАрд╡ рд╕реНрдХреИрд▓рд┐рд╕, рдЖрд░-рд▓рд╛, рдиреЗ рдЯреНрд░рдореНрдк рдХреЗ рджреВрд╕рд░реЗ рдХрд╛рд░реНрдпрдХрд╛рд▓ рдХреЗ рдкрд╣рд▓реЗ 100 рджрд┐рдиреЛрдВ рдХреЗ рдмрд╛рд░реЗ рдореЗрдВ рдХрд╣рд╛ред \"рд╣рдо рдЯрд╣рд▓рдиреЗ рдЬрд╛ рд░рд╣реЗ рд╣реИрдВ рдФрд░ рдЧрдо рдЪрдмрд╛ рд░рд╣реЗ рд╣реИрдВред\"\n",
    "\n",
    "рдХреБрдЫ рд░рд┐рдкрдмреНрд▓рд┐рдХрди рдирдП рдЯреНрд░рдореНрдк рд░рд╛рд╖реНрдЯреНрд░рдкрддрд┐ рдкрдж рдХреА рд╢реБрд░реБрдЖрдд рдореЗрдВ рдлрдВрдбрд┐рдВрдЧ рдХреА рд╕рдордп рд╕реАрдорд╛ рдореЗрдВ рдирд╣реАрдВ рдлрдВрд╕рдирд╛ рдкрд╕рдВрдж рдХрд░реЗрдВрдЧреЗред\"\"\"\n",
    "result = pipeline(example_text)\n",
    "print(\"\\nSummary:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c599c265-f19b-4388-b990-831ed60b8d62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated text:  WASHINGTON, DC тАУ With Congress returning this week to make one final move before it closes, it faces a major deadline on December 20 to avoid shutting down the government. Democrats and Republicans seem resigned to pushing through a decision, or CR, that would temporarily fund the government until early 2025 тАУ probably in March тАУ when they run out of time to agree on full funding this year.\n",
      "\n",
      "Summary: Democrats and Republicans seem resigned to pushing through a decision that would temporarily fund the government until early 2025.\n"
     ]
    }
   ],
   "source": [
    "example_text = \"\"\"┘И╪з╪┤┘Ж╪╖┘Ж тАУ ┘Е╪╣ ╪╣┘И╪п╪й ╪з┘Д┘Г┘И┘Ж╪м╪▒╪│ ┘З╪░╪з ╪з┘Д╪г╪│╪и┘И╪╣ ┘Д┘Д┘В┘К╪з┘Е ╪и┘Е┘И╪м╪й ╪г╪о┘К╪▒╪й ┘Е┘Ж ╪з┘Д┘Ж╪┤╪з╪╖ ┘В╪и┘Д ╪г┘Ж ┘К╪о╪к╪к┘Е ╪м┘Д╪│╪к┘З╪М ┘Б╪е┘Ж┘З ┘К┘И╪з╪м┘З ┘Е┘И╪╣╪п┘Л╪з ┘Ж┘З╪з╪ж┘К┘Л╪з ╪▒╪ж┘К╪│┘К┘Л╪з ┘Б┘К 20 ╪п┘К╪│┘Е╪и╪▒ ┘Д╪к╪м┘Ж╪и ╪е╪║┘Д╪з┘В ╪з┘Д╪н┘Г┘И┘Е╪й.\n",
    "\n",
    "┘К╪и╪п┘И ╪г┘Ж ╪з┘Д╪п┘К┘Е┘В╪▒╪з╪╖┘К┘К┘Ж ┘И╪з┘Д╪м┘Е┘З┘И╪▒┘К┘К┘Ж ┘Е╪│╪к╪│┘Д┘Е┘И┘Ж ┘Д╪к┘Е╪▒┘К╪▒ ┘В╪▒╪з╪▒ ┘Е╪│╪к┘Е╪▒╪М ╪г┘И CR╪М ┘Е┘Ж ╪┤╪г┘Ж┘З ╪г┘Ж ┘К┘Е┘И┘Д ╪з┘Д╪н┘Г┘И┘Е╪й ┘Е╪д┘В╪к┘Л╪з ╪н╪к┘Й ╪г┘И╪з╪ж┘Д ╪╣╪з┘Е 2025 - ╪╣┘Д┘Й ╪з┘Д╪г╪▒╪м╪н ┘Б┘К ┘Е╪з╪▒╪│ - ╪н┘К╪л ┘К┘Ж┘Б╪п ╪з┘Д┘И┘В╪к ╪г┘Е╪з┘Е┘З┘Е ┘Д┘Д╪к┘И╪╡┘Д ╪е┘Д┘Й ╪з╪к┘Б╪з┘В ╪к┘Е┘И┘К┘Д ┘Г╪з┘Е┘Д ┘З╪░╪з ╪з┘Д╪╣╪з┘Е. ┘И┘Д┘Е ┘К╪к┘Б┘В ╪з┘Д╪╖╪▒┘Б╪з┘Ж ╪н╪к┘Й ╪╣┘Д┘Й ┘Е╪│╪к┘И┘Й ╪з┘Д╪е┘Ж┘Б╪з┘В ╪з┘Д╪е╪м┘Е╪з┘Д┘К ┘Д┘Д╪│┘Ж╪й ╪з┘Д┘Е╪з┘Д┘К╪й ╪з┘Д╪м╪п┘К╪п╪й╪М ┘Ж╪з┘З┘К┘Г ╪╣┘Ж ┘Г┘К┘Б┘К╪й ╪к╪о╪╡┘К╪╡ ╪з┘Д╪г┘Е┘И╪з┘Д ╪╣╪и╪▒ ╪г╪м╪▓╪з╪б ┘Е┘Ж ╪з┘Д╪н┘Г┘И┘Е╪й.\n",
    "\n",
    "╪г┘Д┘Е╪н ╪▓╪╣┘К┘Е ╪з┘Д╪г╪║┘Д╪и┘К╪й ┘Б┘К ┘Е╪м┘Д╪│ ╪з┘Д╪┤┘К┘И╪о ╪к╪┤╪з┘Г ╪┤┘И┘Е╪▒╪М ╪п┘К┘Е┘В╪▒╪з╪╖┘К ┘Е┘Ж ┘И┘Д╪з┘К╪й ┘Ж┘К┘И┘К┘И╪▒┘Г╪М ╪е┘Д┘Й ╪н╪к┘Е┘К╪й ┘Е╪┤╪▒┘И╪╣ ┘В╪з┘Ж┘И┘Ж ┘В╪╡┘К╪▒ ╪з┘Д╪г╪м┘Д ┘К┘И┘Е ╪з┘Д╪з╪л┘Ж┘К┘Ж╪М ┘В╪з╪ж┘Д╪з┘Л: \"┘Ж╪н┘Ж ╪и╪н╪з╪м╪й ╪е┘Д┘Й ╪е╪и┘В╪з╪б ╪з┘Д╪г╪н┘Г╪з┘Е ╪з┘Д┘Е╪л┘К╪▒╪й ┘Д┘Д╪о┘Д╪з┘Б ┘И╪║┘К╪▒ ╪з┘Д╪╢╪▒┘И╪▒┘К╪й ╪о╪з╪▒╪м ╪г┘К ╪к┘Е╪п┘К╪п ┘Д┘Д╪к┘Е┘И┘К┘Д ╪з┘Д╪н┘Г┘И┘Е┘К╪М ┘И╪е┘Д╪з ┘Б╪│┘К┘Г┘И┘Ж ┘Е┘Ж ╪з┘Д╪╡╪╣╪и ╪к┘Е╪▒┘К╪▒ ┘Е╪┤╪▒┘И╪╣ ┘В╪з┘Ж┘И┘Ж\". CR ┘Б┘К ╪з┘Д┘И┘В╪к ╪з┘Д┘Е┘Ж╪з╪│╪и.\n",
    "\n",
    "┘И╪и╪з┘Д┘Ж╪│╪и╪й ┘Д┘Д╪м┘Е┘З┘И╪▒┘К┘К┘Ж╪М ┘Б╪е┘Ж ┘З╪░╪з ╪│┘К┘Б ╪░┘И ╪н╪п┘К┘Ж.\n",
    "\n",
    "╪з┘Д╪м╪з┘Ж╪и ╪з┘Д╪е┘К╪м╪з╪и┘К ╪и╪з┘Д┘Ж╪│╪и╪й ┘Д┘Д╪м┘Е┘З┘И╪▒┘К┘К┘Ж ┘Б┘К ╪к╪н╪п┘К╪п ╪з┘Д┘Е┘И╪╣╪п ╪з┘Д┘Ж┘З╪з╪ж┘К ┘З┘И ╪г┘Ж┘З┘Е ╪│┘К┘Г┘И┘Ж ┘Д╪п┘К┘З┘Е ╪з┘Д┘Е╪▓┘К╪п ┘Е┘Ж ╪з┘Д┘Ж┘Б┘И╪░ ┘Д╪к╪┤┘Г┘К┘Д ╪з┘Д╪к┘Е┘И┘К┘Д ╪з┘Д╪н┘Г┘И┘Е┘К ┘Б┘К ╪з┘Д╪╣╪з┘Е ╪з┘Д╪м╪п┘К╪п╪М ┘Е╪╣ ╪╣┘И╪п╪й ╪з┘Д╪▒╪ж┘К╪│ ╪з┘Д┘Е┘Ж╪к╪о╪и ╪п┘И┘Ж╪з┘Д╪п ╪к╪▒╪з┘Е╪и ╪е┘Д┘Й ╪з┘Д╪и┘К╪к ╪з┘Д╪г╪и┘К╪╢ ┘И╪│┘К╪╖╪▒╪й ╪з┘Д╪н╪▓╪и ╪з┘Д╪м┘Е┘З┘И╪▒┘К ╪╣┘Д┘Й ┘Е╪м┘Д╪│ ╪з┘Д╪┤┘К┘И╪о ┘И╪з┘Д╪н┘Б╪з╪╕ ╪╣┘Д┘Й ╪г╪║┘Д╪и┘К╪й ╪╢┘К┘В╪й ┘Б┘К ┘Е╪м┘Д╪│ ╪з┘Д┘Ж┘И╪з╪и.\n",
    "\n",
    "╪з┘Д╪м╪з┘Ж╪и ╪з┘Д╪│┘Д╪и┘К ╪з┘Д┘Г╪и┘К╪▒ ┘З┘И ╪г┘Ж┘З ╪│┘К╪н╪п╪п ┘Е┘И╪╣╪п┘Л╪з ┘Ж┘З╪з╪ж┘К┘Л╪з ╪н╪з╪│┘Е┘Л╪з ┘Б┘К ┘И┘В╪к ┘Е╪и┘Г╪▒ ┘Е┘Ж ╪▒╪ж╪з╪│╪й ╪к╪▒╪з┘Е╪и╪М ┘Е┘Е╪з ┘В╪п ┘К╪│╪к╪║╪▒┘В ┘И┘В╪к┘Л╪з ╪л┘Е┘К┘Ж┘Л╪з ╪и╪╣┘К╪п┘Л╪з ╪╣┘Ж ╪к╪г┘Г┘К╪п ┘Е╪▒╪┤╪н┘К┘З ┘Е┘Ж ╪о┘Д╪з┘Д ┘Е╪м┘Д╪│ ╪з┘Д╪┤┘К┘И╪о ┘И┘Е┘Ж ┘Е╪┤╪▒┘И╪╣ ┘В╪з┘Ж┘И┘Ж ╪з┘Д╪н╪▓╪и ╪з┘Д┘Г╪и┘К╪▒ ╪з┘Д╪░┘К ┘К╪к╪╖┘Д╪╣ ╪е┘Д┘К┘З ╪з┘Д╪м┘Е┘З┘И╪▒┘К┘И┘Ж ┘Д╪к┘Е╪п┘К╪п ╪к╪о┘Б┘К╪╢╪з╪к┘З ╪з┘Д╪╢╪▒┘К╪и┘К╪й ┘И╪к╪╣╪▓┘К╪▓ ╪з┘Д┘З╪м╪▒╪й. ┘И╪г╪м┘Ж╪п╪й ╪г┘Е┘Ж ╪з┘Д╪н╪п┘И╪п.\n",
    "\n",
    "┘И╪г╪╢╪з┘Б ┘Г┘К┘Ж┘К╪п┘К ╪г┘Ж┘З ┘Е┘Ж ╪з┘Д┘Е╪▒╪м╪н ╪г┘Ж ┘К╪╣┘Д┘В ╪з┘Д┘Г┘И┘Ж╪м╪▒╪│ \"30 [┘Е┘Д┘К╪з╪▒ ╪п┘И┘Д╪з╪▒] ╪е┘Д┘Й 40 ┘Е┘Д┘К╪з╪▒ ╪п┘И┘Д╪з╪▒ ┘Е┘Ж ╪з┘Д╪е╪║╪з╪л╪й ┘Б┘К ╪н╪з┘Д╪з╪к ╪з┘Д┘Г┘И╪з╪▒╪л\" ╪е┘Д┘Й ╪з┘Д╪м┘Е┘З┘И╪▒┘К╪й ╪з┘Д╪к╪┤┘К┘Г┘К╪й╪М ╪и┘Е╪з ┘Б┘К ╪░┘Д┘Г ╪к┘Е┘И┘К┘Д ╪з┘Д┘И┘Д╪з┘К╪з╪к ╪з┘Д╪к┘К ╪╢╪▒╪и╪к┘З╪з ╪з┘Д╪г╪╣╪з╪╡┘К╪▒ ┘З╪░╪з ╪з┘Д╪╣╪з┘Е. ┘И┘В╪з┘Д: \"┘Д┘Ж ┘К┘Г┘И┘Ж ╪░┘Д┘Г ┘Г╪з┘Б┘К╪з╪М ┘Д┘Г┘Ж┘З ╪│┘К┘Г┘И┘Ж ┘Г╪з┘Б┘К╪з ┘Д┘Д╪и╪п╪б\".\"\"\"\n",
    "\n",
    "result = pipeline(example_text)\n",
    "print(\"\\nSummary:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "35372c14-1da9-46c6-b45b-a980c642b521",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200, 'num_beams': 5, 'forced_bos_token_id': 250004}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./translation_model/tokenizer_config.json',\n",
       " './translation_model/special_tokens_map.json',\n",
       " './translation_model/sentencepiece.bpe.model',\n",
       " './translation_model/added_tokens.json')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the translation model and tokenizer\n",
    "translation_model.save_pretrained(\"./translation_model\")\n",
    "translation_tokenizer.save_pretrained(\"./translation_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd742bcd-d3f3-4899-a6c3-5315ab910ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_model.save_pretrained(\"./lora_summarization_model\")\n",
    "summarization_tokenizer.save_pretrained(\"./lora_summarization_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83325d2-1649-4eb0-bb03-c12ed7729b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m125"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
